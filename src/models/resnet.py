import torch
import torchvision.models as models
import torch.nn as nn
import torch.nn.init as init
import math


def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False # Freeze

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    def norm_cdf(x):
        # Computes the standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse CDF transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean and std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

# Custom weight initialization function using model.modules()
def initialize_weights(model):
    for layer in model.modules():
        if isinstance(layer, nn.Conv2d):
            init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')
            if layer.bias is not None:
                init.constant_(layer.bias, 0)
        elif isinstance(layer, nn.BatchNorm2d):
            init.constant_(layer.weight, 1)
            init.constant_(layer.bias, 0)
        elif isinstance(layer, nn.Linear):
            trunc_normal_(layer.weight, std=0.02)  # Apply the custom truncated normal initialization
            if layer.bias is not None:
                init.constant_(layer.bias, 0)
        elif isinstance(layer, nn.LayerNorm):
            init.constant_(layer.bias, 0)
            init.constant_(layer.weight, 1.0)


# Define a new model that changes the first conv1 layer based on the mode
class ResNet18_n(nn.Module):
    def __init__(self, n, mode="default", freeze=False, projection=False):
        super(ResNet18_n, self).__init__()
        self.freeze = freeze
        self.projection = projection

        # Load the pretrained ResNet-18 model
        resnet18 = models.resnet18(pretrained=True)
        set_parameter_requires_grad(resnet18, feature_extracting=self.freeze)  # True: freeze

        if mode == "lidar":
            # Create a new conv1 layer instead of modifying the original
            conv1 = nn.Conv2d(
                in_channels=1,
                out_channels=resnet18.conv1.out_channels,
                kernel_size=resnet18.conv1.kernel_size,
                stride=resnet18.conv1.stride,
                padding=resnet18.conv1.padding,
                bias=False
            )
            # Initialize the weights of the new conv1 layer: USE DEFAULT: KAIMING HE
            # CHECK WHY IT DOESNT WORK WITH THE BELOW INITIALIZATION
            # with torch.no_grad():
            #     conv1.weight = nn.Parameter(resnet18.conv1.weight.sum(dim=1, keepdim=True))
        else:
            # Use the original conv1 layer
            conv1 = resnet18.conv1

        # List of available blocks in ResNet-18
        available_blocks = [resnet18.layer1, resnet18.layer2, resnet18.layer3, resnet18.layer4]

        # Assert that n does not exceed the number of available blocks
        assert n <= len(available_blocks), f"Requested {n} blocks, but only {len(available_blocks)} are available."

        # Extracting the initial convolutional layer, batch norm, and relu
        self.initial_layers = nn.Sequential(
            conv1,
            resnet18.bn1,
            resnet18.relu,
            resnet18.maxpool
        )

        # Collect the blocks iteratively
        blocks = []
        for i in range(n):
            blocks.append(available_blocks[i])

        # Combine the selected blocks into a sequential model
        self.blocks = nn.Sequential(*blocks)

        last_block_channels = self.get_last_layer_channels()
        # Optionally add the projection head (average pooling + MLP with 1000 neurons)
        if self.projection:
            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive average pooling to 1x1
            self.fc = nn.Linear(last_block_channels, 1000) # Final projection to 1000 neurons

    def get_last_layer_channels(self):
        """Get the output channels of the last convolutional layer in the selected block."""
        # Get the last block in the model
        last_block = list(self.blocks.children())[-1]

        # Get the last BasicBlock in the last block
        last_basic_block = list(last_block.children())[-1]

        # The last BasicBlock should have a conv2 layer, which is the last convolutional layer
        last_conv_layer = last_basic_block.conv2

        # Return the number of output channels of the last convolutional layer
        return last_conv_layer.out_channels

    def forward(self, x):
        flag = False
        if len(x.shape) == 3:
            x = x.unsqueeze(0)
            flag = True

        x = self.initial_layers(x)
        x = self.blocks(x)

        # If projection is enabled, apply avg pooling and the projection MLP
        if self.projection:
            x = self.avgpool(x)
            x = torch.flatten(x, 1)
            x = self.fc(x)

        if flag:
            x = x.squeeze(0)
            flag = False
        return x

def resnet18_all_im(mode="default"):
    model = ResNet18_n(n=4, mode=mode)
    initialize_weights(model=model)
    return model

def resnet18_all_lid(mode="lidar"):
    model = ResNet18_n(n=4, mode=mode)
    initialize_weights(model=model)
    return model

def resnet18_small_im(mode="default"):
    model = ResNet18_n(n=2, mode=mode)
    return model

def resnet18_small_lid(mode="lidar"):
    model = ResNet18_n(n=2, mode=mode)
    return model

def resnet18_instance_small_im(mode="default", projection=True):
    model = ResNet18_n(n=2, mode=mode, projection=projection)
    return model

def resnet18_instance_small_lid(mode="lidar", projection=True):
    model = ResNet18_n(n=2, mode=mode, projection=projection)
    return model

